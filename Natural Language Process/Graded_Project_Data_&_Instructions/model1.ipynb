{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Team Members:\n",
    "- Amir Mobayen\n",
    "- Leelav Kareem\n",
    "- Nikita Chistyakov\n",
    "\n",
    "## Topic:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Libraries"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "# Basic packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-14T16:13:24.518404665Z",
     "start_time": "2023-07-14T16:13:24.474933654Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# About the dataset:\n",
    "List of tweet texts with emotion labels like joy, sadness, fear, angerâ€¦\n",
    "Dataset is split into train, test and validation sets for building the machine learning model. At first, you are\n",
    "given only train and test sets. The validation one will be given in the end of the project for you to check\n",
    "the final performance of your algorithm (to make sure there is no overfitting over the test data).\n",
    "You can work on this project on group of one, two or three students. This exercise is mandatory, not\n",
    "giving it back is equivalent to getting to lowest grade"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Goal:\n",
    "- Train different kind of models able to classify each text according to the sentiment mainly present\n",
    "in it\n",
    "- Compare the results of your different models and try to analyze and explain the differences"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Parameters"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "data_file = './NLP_exam_emotions_dataset/train.txt'\n",
    "test_flie = './NLP_exam_emotions_dataset/test.txt'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-14T16:11:53.216737334Z",
     "start_time": "2023-07-14T16:11:53.196385292Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preparing Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "(                             i didnt feel humiliated  sadness\n 0  i can go from feeling so hopeless to so damned...  sadness\n 1   im grabbing a minute to post i feel greedy wrong    anger\n 2  i am ever feeling nostalgic about the fireplac...     love\n 3                               i am feeling grouchy    anger\n 4  ive been feeling a little burdened lately wasn...  sadness,\n   im feeling rather rotten so im not very ambitious right now  sadness\n 0          im updating my blog because i feel shitty           sadness\n 1  i never make her separate from me because i do...           sadness\n 2  i left with my bouquet of red and yellow tulip...               joy\n 3    i was feeling a little vain when i did this one           sadness\n 4  i cant walk into a shop anywhere where i do no...              fear)"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(data_file, delimiter=';', header=0)\n",
    "test_data = pd.read_csv(test_flie, delimiter=';', header=0)\n",
    "\n",
    "train_data.head(), test_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-14T16:11:53.243601068Z",
     "start_time": "2023-07-14T16:11:53.199407359Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15999 entries, 0 to 15998\n",
      "Data columns (total 2 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   i didnt feel humiliated  15999 non-null  object\n",
      " 1   sadness                  15999 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 250.1+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1999 entries, 0 to 1998\n",
      "Data columns (total 2 columns):\n",
      " #   Column                                                       Non-Null Count  Dtype \n",
      "---  ------                                                       --------------  ----- \n",
      " 0   im feeling rather rotten so im not very ambitious right now  1999 non-null   object\n",
      " 1   sadness                                                      1999 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 31.4+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": "(None, None)"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.info(), test_data.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-14T16:11:53.244015417Z",
     "start_time": "2023-07-14T16:11:53.242114133Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    tokenizer = Tokenizer()\n",
    "    tokenizer.fit_on_texts(text)\n",
    "    sequences = tokenizer.texts_to_sequences(text)\n",
    "    max_len = max([len(seq) for seq in sequences])\n",
    "    vocab_size = len(tokenizer.word_index) + 1\n",
    "    return pad_sequences(sequences, maxlen=max_len), max_len, vocab_size"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-14T16:11:53.244259448Z",
     "start_time": "2023-07-14T16:11:53.242623100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "train_x, max_len, vocab_size = tokenizer(train_data.iloc[:,0])\n",
    "test_x = tokenizer(test_data.iloc[:,0])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-14T16:11:53.561053116Z",
     "start_time": "2023-07-14T16:11:53.266321605Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "train_y = train_data.iloc[:,1]\n",
    "test_y = test_data.iloc[:,1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-14T16:11:53.564036866Z",
     "start_time": "2023-07-14T16:11:53.561355054Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 18:11:55.031899: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, 100, input_length=max_len))\n",
    "model.add(tf.keras.layers.Conv1D(128, 5, activation='relu'))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(64, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(4, activation='softmax'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-14T16:11:55.127846651Z",
     "start_time": "2023-07-14T16:11:53.565836213Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-14 18:11:55.589678: W tensorflow/core/framework/op_kernel.cc:1807] OP_REQUIRES failed at cast_op.cc:121 : UNIMPLEMENTED: Cast string to float is not supported\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": "Graph execution error:\n\nDetected at node 'Cast_22' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n      handle._run()\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_28982/2811918700.py\", line 2, in <module>\n      model.fit(train_x, train_y, epochs=10, batch_size=32, validation_split=0.2)\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/keras/engine/training.py\", line 1055, in train_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/keras/engine/training.py\", line 1149, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/keras/engine/compile_utils.py\", line 605, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/keras/utils/metrics_utils.py\", line 77, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/keras/metrics/base_metric.py\", line 140, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/keras/metrics/base_metric.py\", line 676, in update_state\n      y_true = tf.cast(y_true, self._dtype)\nNode: 'Cast_22'\nCast string to float is not supported\n\t [[{{node Cast_22}}]] [Op:__inference_train_function_1229]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUnimplementedError\u001B[0m                        Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[23], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(loss\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msparse_categorical_crossentropy\u001B[39m\u001B[38;5;124m'\u001B[39m, optimizer\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124madam\u001B[39m\u001B[38;5;124m'\u001B[39m, metrics\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccuracy\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m----> 2\u001B[0m model\u001B[38;5;241m.\u001B[39mfit(train_x, train_y, epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m32\u001B[39m, validation_split\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.2\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/keras/utils/traceback_utils.py:70\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n\u001B[1;32m     68\u001B[0m     \u001B[38;5;66;03m# To get the full stack trace, call:\u001B[39;00m\n\u001B[1;32m     69\u001B[0m     \u001B[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001B[39;00m\n\u001B[0;32m---> 70\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m e\u001B[38;5;241m.\u001B[39mwith_traceback(filtered_tb) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m filtered_tb\n",
      "File \u001B[0;32m~/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:52\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     51\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 52\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_Execute(ctx\u001B[38;5;241m.\u001B[39m_handle, device_name, op_name,\n\u001B[1;32m     53\u001B[0m                                       inputs, attrs, num_outputs)\n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     55\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mUnimplementedError\u001B[0m: Graph execution error:\n\nDetected at node 'Cast_22' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 711, in start\n      self.io_loop.start()\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/asyncio/base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/asyncio/base_events.py\", line 1922, in _run_once\n      handle._run()\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 411, in do_execute\n      res = shell.run_cell(\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 531, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3006, in run_cell\n      result = self._run_cell(\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3061, in _run_cell\n      result = runner(coro)\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3266, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3445, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3505, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_28982/2811918700.py\", line 2, in <module>\n      model.fit(train_x, train_y, epochs=10, batch_size=32, validation_split=0.2)\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/keras/engine/training.py\", line 1055, in train_step\n      return self.compute_metrics(x, y, y_pred, sample_weight)\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/keras/engine/training.py\", line 1149, in compute_metrics\n      self.compiled_metrics.update_state(y, y_pred, sample_weight)\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/keras/engine/compile_utils.py\", line 605, in update_state\n      metric_obj.update_state(y_t, y_p, sample_weight=mask)\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/keras/utils/metrics_utils.py\", line 77, in decorated\n      update_op = update_state_fn(*args, **kwargs)\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/keras/metrics/base_metric.py\", line 140, in update_state_fn\n      return ag_update_state(*args, **kwargs)\n    File \"/home/amir/anaconda3/envs/tf_gpu/lib/python3.11/site-packages/keras/metrics/base_metric.py\", line 676, in update_state\n      y_true = tf.cast(y_true, self._dtype)\nNode: 'Cast_22'\nCast string to float is not supported\n\t [[{{node Cast_22}}]] [Op:__inference_train_function_1229]"
     ]
    }
   ],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(train_x, train_y, epochs=10, batch_size=32, validation_split=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-14T16:11:55.640895358Z",
     "start_time": "2023-07-14T16:11:55.128144892Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss, accuracy = model.evaluate(test_x, test_y)\n",
    "print('Test Loss:', loss)\n",
    "print('Test Accuracy:', accuracy)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-07-14T16:11:55.640712859Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
