{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Team Members:\n",
    "- Amirhossein Mobayen\n",
    "- Mohamed amine Filali\n",
    "- Nikita Chistyakov\n",
    "- Rym Mehdi\n",
    "- Skander Ben brik\n",
    "\n",
    "## Topic:\n",
    "AI Chess Master"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Objective:\n",
    "BuildaVisionAIwhichunderstandsapositionbylookingattheboard!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 1: Dataset Preparation\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Download the dataset from Kaggle and extract the relevant files.\n",
    "# URL: https://www.kaggle.com/koryakinp/chess-positions\n",
    "\n",
    "# Define the input image size for the model\n",
    "input_shape = (224, 224, 3)\n",
    "\n",
    "# Define the path to the dataset directory\n",
    "dataset_dir = 'path/to/dataset'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 2: Data Preprocessing"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load and preprocess a chessboard image\n",
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=input_shape[:2])\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = img_array.reshape((1,) + img_array.shape)\n",
    "    img_array = img_array.astype('float32')\n",
    "    img_array /= 255.0\n",
    "    return img_array"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Iterate through the dataset directory to preprocess all images\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "# Iterate through each subdirectory (class) in the dataset directory\n",
    "for subdirectory in os.listdir(dataset_dir):\n",
    "    subdirectory_path = os.path.join(dataset_dir, subdirectory)\n",
    "    if os.path.isdir(subdirectory_path):\n",
    "        # Iterate through each image file in the subdirectory\n",
    "        for image_file in os.listdir(subdirectory_path):\n",
    "            image_path = os.path.join(subdirectory_path, image_file)\n",
    "            image_paths.append(image_path)\n",
    "            labels.append(subdirectory)  # Assuming subdirectory name is the label\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "num_classes = len(set(labels))\n",
    "labels = tf.keras.utils.to_categorical(labels, num_classes=num_classes)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_images, test_images, train_labels, test_labels = train_test_split(image_paths, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the training images\n",
    "train_images_preprocessed = []\n",
    "for image_path in train_images:\n",
    "    preprocessed_image = preprocess_image(image_path)\n",
    "    train_images_preprocessed.append(preprocessed_image)\n",
    "train_images_preprocessed = np.array(train_images_preprocessed)\n",
    "\n",
    "# Preprocess the testing images\n",
    "test_images_preprocessed = []\n",
    "for image_path in test_images:\n",
    "    preprocessed_image = preprocess_image(image_path)\n",
    "    test_images_preprocessed.append(preprocessed_image)\n",
    "test_images_preprocessed = np.array(test_images_preprocessed)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 3: Model Selection and Architecture"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the VGG16 model without the top (fully connected) layers\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "# Add a global average pooling layer and a fully connected layer on top\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 4: Model Training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Compile the model with an appropriate loss function and optimizer\n",
    "model.compile(optimizer=SGD(lr=0.001, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images_preprocessed, train_labels, batch_size=32, epochs=10, validation_data=(test_images_preprocessed, test_labels))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 5: Model Evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluate the model on the testing dataset\n",
    "test_loss, test_accuracy = model.evaluate(test_images, test_labels)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Step 6: Model Deployment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save the trained model weights for future use\n",
    "model.save('chessboard_model.h5')\n",
    "\n",
    "# Load the saved model\n",
    "loaded_model = tf.keras.models.load_model('chessboard_model.h5')\n",
    "\n",
    "# Preprocess a chessboard image and make predictions\n",
    "image_path = 'path/to/chessboard_image.jpg'\n",
    "preprocessed_image = preprocess_image(image_path)\n",
    "preprocessed_image = np.expand_dims(preprocessed_image, axis=0)\n",
    "predictions = loaded_model.predict(preprocessed_image)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Convert predictions to FEN format\n",
    "def convert_predictions_to_fen(predictions):\n",
    "    # Implement your conversion logic here\n",
    "    return 'FEN position'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Convert predictions to FEN format\n",
    "predicted_position = convert_predictions_to_fen(predictions)\n",
    "\n",
    "# Print the predicted position\n",
    "print(predicted_position)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
