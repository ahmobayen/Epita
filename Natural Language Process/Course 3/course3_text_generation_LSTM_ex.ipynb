{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "course3_text_generation_LSTM_ex.ipynb",
   "provenance": [
    {
     "file_id": "1W5YJEt9tn5UmAVGXG1iKylxbv76zZpbQ",
     "timestamp": 1623887037576
    }
   ],
   "authorship_tag": "ABX9TyNQRK4df74efJqVXGlwN6SG"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "m9Bzo0D29mj-",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1623891557725,
     "user_tz": -120,
     "elapsed": 2259,
     "user": {
      "displayName": "Romain Benassi",
      "photoUrl": "",
      "userId": "07755091784567448642"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-07-05T08:43:22.673443489Z",
     "start_time": "2023-07-05T08:43:21.139059281Z"
    }
   },
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras.utils as ku\n",
    "import numpy as np\n",
    "import pandas as pd"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-05 10:43:21.228953: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-05 10:43:21.260224: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-05 10:43:21.806044: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ti5Q5Xx9Qhxy"
   },
   "source": [
    "Definition of a plot function for training result visualization"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rVKoPUqJ_apr",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1623891561124,
     "user_tz": -120,
     "elapsed": 227,
     "user": {
      "displayName": "Romain Benassi",
      "photoUrl": "",
      "userId": "07755091784567448642"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-07-05T08:43:26.119437377Z",
     "start_time": "2023-07-05T08:43:26.103398201Z"
    }
   },
   "source": [
    "def plot_results(history):\n",
    "    hist_df = pd.DataFrame(history.history)\n",
    "    hist_df.columns = [\"loss\", \"accuracy\", \"val_loss\", \"val_accuracy\"]\n",
    "    hist_df.index = np.arange(1, len(hist_df) + 1)\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=2, sharex=True, figsize=(16, 10))\n",
    "    axs[0].plot(hist_df.val_accuracy, lw=3, label='Validation Accuracy')\n",
    "    axs[0].plot(hist_df.accuracy, lw=3, label='Training Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].grid()\n",
    "    axs[0].legend(loc=0)\n",
    "    axs[1].plot(hist_df.val_loss, lw=3, label='Validation Loss')\n",
    "    axs[1].plot(hist_df.loss, lw=3, label='Training Loss')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].grid()\n",
    "    axs[1].legend(loc=0)\n",
    "\n",
    "    plt.show();"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q61YBz5XQxmt"
   },
   "source": [
    "## Data preproccesing"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mjzitxFS_dpA",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1623891582851,
     "user_tz": -120,
     "elapsed": 19391,
     "user": {
      "displayName": "Romain Benassi",
      "photoUrl": "",
      "userId": "07755091784567448642"
     }
    },
    "outputId": "5f6cbada-c2a1-4bc2-ca28-7047c0b7b900"
   },
   "source": [
    "# Mounting the google drive to google colab in order to load the data files directly from it\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "orUto5KgQ02i"
   },
   "source": [
    "We load a txt file containing Shakespeare sonnets"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "yBPyDBnSEWm0",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1623891587482,
     "user_tz": -120,
     "elapsed": 967,
     "user": {
      "displayName": "Romain Benassi",
      "photoUrl": "",
      "userId": "07755091784567448642"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-07-05T08:43:46.078073251Z",
     "start_time": "2023-07-05T08:43:46.075659015Z"
    }
   },
   "source": [
    "data = open('sonnets.txt').read()\n",
    "\n",
    "corpus = data.lower().split(\"\\n\")"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZM7_ViIGe0NW",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1623891601968,
     "user_tz": -120,
     "elapsed": 213,
     "user": {
      "displayName": "Romain Benassi",
      "photoUrl": "",
      "userId": "07755091784567448642"
     }
    },
    "outputId": "950663a1-b636-4585-e8f3-bda789e0089b",
    "ExecuteTime": {
     "end_time": "2023-07-05T08:43:48.549335697Z",
     "start_time": "2023-07-05T08:43:48.542482371Z"
    }
   },
   "source": [
    "corpus[0:10]"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "['from fairest creatures we desire increase,',\n \"that thereby beauty's rose might never die,\",\n 'but as the riper should by time decease,',\n 'his tender heir might bear his memory:',\n 'but thou, contracted to thine own bright eyes,',\n \"feed'st thy light'st flame with self-substantial fuel,\",\n 'making a famine where abundance lies,',\n 'thyself thy foe, to thy sweet self too cruel.',\n \"thou that art now the world's fresh ornament\",\n 'and only herald to the gaudy spring,']"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3IAn1hV1Seoh"
   },
   "source": [
    "We need to transform each text sentence into token sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oh9kumfjSqIF"
   },
   "source": [
    "Then we need to generate from each token sequence, several token subsequences in order to augment the dataset. **Remember** that we want to learn how to predict the next word of a sentence. A sentence of 5 words can so be used to generate 4 training sequences.\n",
    "\n",
    "e.g. the sentence \"*to be or not to be*\" can give the following training sequences: \n",
    "\n",
    "\"*to* **be**\"\n",
    "\n",
    "\"*to be* **or**\"\n",
    "\n",
    "\"*to be or* **not**\"\n",
    "\n",
    "\"*to be or not* **to**\"\n",
    "\n",
    "\"*to be or not to* **be**\""
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-75oYENbEp3x",
    "ExecuteTime": {
     "end_time": "2023-07-05T09:00:26.601826440Z",
     "start_time": "2023-07-05T09:00:26.551985965Z"
    }
   },
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "# Question 1: use the preprocessing steps learned in course3_text_sequence_preprocessing_ex.ipynb to create the padded sequences needed to train the model\n",
    "# Hint: Be careful about the length you will use for the padding sequences AND about where you put the extra zero coming from the padding (at the beginning of the sequence or at the end)\n",
    "\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "input_sequences = []\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i + 1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "predictors, label = input_sequences[:, :-1], input_sequences[:, -1]"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "[3, 21, 36, 15, 3, 21]"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_text = tokenizer.texts_to_sequences(['to be or not to be'])[0]\n",
    "sequence_text"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-05T09:14:02.266575455Z",
     "start_time": "2023-07-05T09:14:02.218501814Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXnkNk_3qhtw"
   },
   "source": [
    "## Neural network model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tNktnNfFqi16"
   },
   "source": [
    "Build a neural network using at least one LSTM layer\n",
    "\n",
    "(you may have a look at https://keras.io/api/layers/)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jxEWvq3yE3M1",
    "ExecuteTime": {
     "end_time": "2023-07-05T09:39:28.706324878Z",
     "start_time": "2023-07-05T09:39:28.291229211Z"
    }
   },
   "source": [
    "\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "import tensorflow as tf\n",
    "\n",
    "# Question 2: define a neural network model using at least one LSTM layer\n",
    "# Hint1: we advise you to use as first layer an Embedding layer (have a look at course3_sentiment_analysis_LSTM_ex.ipynb for a reminder of how to use it)\n",
    "# Hint2: you can import any additional layers from tensorflow.keras.layers if needed\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    Embedding(total_words, 100, input_length=max_sequence_len - 1),\n",
    "    Bidirectional(LSTM(150, return_sequences=True)),\n",
    "    Dropout(0.2),\n",
    "    LSTM(100),\n",
    "    Dense(total_words/2, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
    "    Dense(total_words, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "# Question 3: define a relevant loss function and optimizer\n",
    "\n",
    "loss_function = 'sparse_categorical_crossentropy'\n",
    "optimizer = 'adam'\n",
    "\n",
    "model.compile(loss=loss_function, optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ],
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-05 11:39:28.411669: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-05 11:39:28.412540: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-05 11:39:28.413228: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2023-07-05 11:39:28.480753: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-05 11:39:28.506509: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-05 11:39:28.507153: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-05 11:39:28.507738: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 10, 100)           321100    \n",
      "                                                                 \n",
      " bidirectional_2 (Bidirectio  (None, 10, 300)          301200    \n",
      " nal)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 10, 300)           0         \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 100)               160400    \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1605)              162105    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3211)              5156866   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,101,671\n",
      "Trainable params: 6,101,671\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-05 11:39:28.620999: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-07-05 11:39:28.621927: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-07-05 11:39:28.622558: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "AhTePq5sE5TC"
   },
   "source": [
    "# Question 4: train your model with relevant parameters\n",
    "\n",
    "predictors = predictors\n",
    "label = label\n",
    "epochs_value = 30\n",
    "validation_split_value = ??????\n",
    "\n",
    "history = model.fit(predictors, label, epochs=epochs_value, verbose=1, validation_split=validation_split_value)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZAASHMx76TgY"
   },
   "source": [
    "## Result visualization"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pgKycPomE_Dc"
   },
   "source": [
    "plot_results(history)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HbWmhe3Jr5Zz"
   },
   "source": [
    "## Text generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o0SXL2-Yr7o_"
   },
   "source": [
    "You can now use your model to sequentially generate new words from a given uncomplete sentence"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "h9i3YkKWF4w0"
   },
   "source": [
    "seed_text = \"Put here the begining of a sentence of your own\"\n",
    "nb_additional_words = 100\n",
    "\n",
    "# Question 5: generate nb_additional_words at the end of seed_text according to your trained model\n"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}
