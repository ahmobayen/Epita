{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "CKDCymVPVKIK"
   ]
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "premium"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "*This Notebook has been created by PALISSON Antoine.*<br>\n"
   ],
   "metadata": {
    "id": "4FMp9gtS-2LO"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Basic packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.model_selection\n",
    "\n",
    "# Sklearn \n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf"
   ],
   "metadata": {
    "id": "XxHArnZntSDY",
    "ExecuteTime": {
     "start_time": "2023-05-02T12:02:50.594665Z",
     "end_time": "2023-05-02T12:02:54.827592Z"
    }
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Datasets"
   ],
   "metadata": {
    "id": "CKDCymVPVKIK"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# for first part\n",
    "\n",
    "data = fetch_openml('california_housing', version=1, parser='auto')\n",
    "housing = pd.concat([data['target'], data['data']], axis=1).dropna()\n",
    "housing.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "s6IdWw14XJZA",
    "outputId": "474ab237-7deb-4eb2-d86f-f1210c5459f9",
    "ExecuteTime": {
     "start_time": "2023-05-02T12:02:54.829593Z",
     "end_time": "2023-05-02T12:02:54.890728Z"
    }
   },
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "   median_house_value  longitude  latitude  housing_median_age  total_rooms   \n0              452600    -122.23     37.88                  41          880  \\\n1              358500    -122.22     37.86                  21         7099   \n2              352100    -122.24     37.85                  52         1467   \n3              341300    -122.25     37.85                  52         1274   \n4              342200    -122.25     37.85                  52         1627   \n\n   total_bedrooms  population  households  median_income ocean_proximity  \n0           129.0         322         126         8.3252        NEAR BAY  \n1          1106.0        2401        1138         8.3014        NEAR BAY  \n2           190.0         496         177         7.2574        NEAR BAY  \n3           235.0         558         219         5.6431        NEAR BAY  \n4           280.0         565         259         3.8462        NEAR BAY  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>median_house_value</th>\n      <th>longitude</th>\n      <th>latitude</th>\n      <th>housing_median_age</th>\n      <th>total_rooms</th>\n      <th>total_bedrooms</th>\n      <th>population</th>\n      <th>households</th>\n      <th>median_income</th>\n      <th>ocean_proximity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>452600</td>\n      <td>-122.23</td>\n      <td>37.88</td>\n      <td>41</td>\n      <td>880</td>\n      <td>129.0</td>\n      <td>322</td>\n      <td>126</td>\n      <td>8.3252</td>\n      <td>NEAR BAY</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>358500</td>\n      <td>-122.22</td>\n      <td>37.86</td>\n      <td>21</td>\n      <td>7099</td>\n      <td>1106.0</td>\n      <td>2401</td>\n      <td>1138</td>\n      <td>8.3014</td>\n      <td>NEAR BAY</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>352100</td>\n      <td>-122.24</td>\n      <td>37.85</td>\n      <td>52</td>\n      <td>1467</td>\n      <td>190.0</td>\n      <td>496</td>\n      <td>177</td>\n      <td>7.2574</td>\n      <td>NEAR BAY</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>341300</td>\n      <td>-122.25</td>\n      <td>37.85</td>\n      <td>52</td>\n      <td>1274</td>\n      <td>235.0</td>\n      <td>558</td>\n      <td>219</td>\n      <td>5.6431</td>\n      <td>NEAR BAY</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>342200</td>\n      <td>-122.25</td>\n      <td>37.85</td>\n      <td>52</td>\n      <td>1627</td>\n      <td>280.0</td>\n      <td>565</td>\n      <td>259</td>\n      <td>3.8462</td>\n      <td>NEAR BAY</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# for classification\n",
    "\n",
    "data = fetch_openml(\"wdbc\", version=1, parser='auto')\n",
    "breast = pd.concat([data['target'], data['data']], axis=1).dropna()\n",
    "breast.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 236
    },
    "id": "irXUHe88ML9J",
    "outputId": "c78e7868-3d9e-43e6-9224-82620e00b96f",
    "ExecuteTime": {
     "start_time": "2023-05-02T12:02:54.893732Z",
     "end_time": "2023-05-02T12:02:55.000254Z"
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "  Class     V1     V2      V3      V4       V5       V6      V7       V8   \n0     2  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001  0.14710  \\\n1     2  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869  0.07017   \n2     2  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974  0.12790   \n3     2  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414  0.10520   \n4     2  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980  0.10430   \n\n       V9  ...    V21    V22     V23     V24     V25     V26     V27     V28   \n0  0.2419  ...  25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119  0.2654  \\\n1  0.1812  ...  24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416  0.1860   \n2  0.2069  ...  23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504  0.2430   \n3  0.2597  ...  14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869  0.2575   \n4  0.1809  ...  22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000  0.1625   \n\n      V29      V30  \n0  0.4601  0.11890  \n1  0.2750  0.08902  \n2  0.3613  0.08758  \n3  0.6638  0.17300  \n4  0.2364  0.07678  \n\n[5 rows x 31 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Class</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>V29</th>\n      <th>V30</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>17.99</td>\n      <td>10.38</td>\n      <td>122.80</td>\n      <td>1001.0</td>\n      <td>0.11840</td>\n      <td>0.27760</td>\n      <td>0.3001</td>\n      <td>0.14710</td>\n      <td>0.2419</td>\n      <td>...</td>\n      <td>25.38</td>\n      <td>17.33</td>\n      <td>184.60</td>\n      <td>2019.0</td>\n      <td>0.1622</td>\n      <td>0.6656</td>\n      <td>0.7119</td>\n      <td>0.2654</td>\n      <td>0.4601</td>\n      <td>0.11890</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>20.57</td>\n      <td>17.77</td>\n      <td>132.90</td>\n      <td>1326.0</td>\n      <td>0.08474</td>\n      <td>0.07864</td>\n      <td>0.0869</td>\n      <td>0.07017</td>\n      <td>0.1812</td>\n      <td>...</td>\n      <td>24.99</td>\n      <td>23.41</td>\n      <td>158.80</td>\n      <td>1956.0</td>\n      <td>0.1238</td>\n      <td>0.1866</td>\n      <td>0.2416</td>\n      <td>0.1860</td>\n      <td>0.2750</td>\n      <td>0.08902</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>19.69</td>\n      <td>21.25</td>\n      <td>130.00</td>\n      <td>1203.0</td>\n      <td>0.10960</td>\n      <td>0.15990</td>\n      <td>0.1974</td>\n      <td>0.12790</td>\n      <td>0.2069</td>\n      <td>...</td>\n      <td>23.57</td>\n      <td>25.53</td>\n      <td>152.50</td>\n      <td>1709.0</td>\n      <td>0.1444</td>\n      <td>0.4245</td>\n      <td>0.4504</td>\n      <td>0.2430</td>\n      <td>0.3613</td>\n      <td>0.08758</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>11.42</td>\n      <td>20.38</td>\n      <td>77.58</td>\n      <td>386.1</td>\n      <td>0.14250</td>\n      <td>0.28390</td>\n      <td>0.2414</td>\n      <td>0.10520</td>\n      <td>0.2597</td>\n      <td>...</td>\n      <td>14.91</td>\n      <td>26.50</td>\n      <td>98.87</td>\n      <td>567.7</td>\n      <td>0.2098</td>\n      <td>0.8663</td>\n      <td>0.6869</td>\n      <td>0.2575</td>\n      <td>0.6638</td>\n      <td>0.17300</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>20.29</td>\n      <td>14.34</td>\n      <td>135.10</td>\n      <td>1297.0</td>\n      <td>0.10030</td>\n      <td>0.13280</td>\n      <td>0.1980</td>\n      <td>0.10430</td>\n      <td>0.1809</td>\n      <td>...</td>\n      <td>22.54</td>\n      <td>16.67</td>\n      <td>152.20</td>\n      <td>1575.0</td>\n      <td>0.1374</td>\n      <td>0.2050</td>\n      <td>0.4000</td>\n      <td>0.1625</td>\n      <td>0.2364</td>\n      <td>0.07678</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 31 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Regression"
   ],
   "metadata": {
    "id": "DxaB0EZOuLas"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing"
   ],
   "metadata": {
    "id": "-SuD_rn5oivl"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**<font color='blue'>1. Create a validation set and a test set by using respectively 10% and 20% of the data.**\n",
    "\n",
    "*Tips: You can use the `train_test_split` function from sklearn.*"
   ],
   "metadata": {
    "id": "W6O9HZ97sGo1"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Split the data into training and test sets\n",
    "train_data, test_data = train_test_split(housing, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split the training data further into training and validation sets\n",
    "train_data, validation_data = train_test_split(train_data, test_size=0.1, random_state=42)"
   ],
   "metadata": {
    "id": "KbpxCiqTgHI5",
    "ExecuteTime": {
     "start_time": "2023-05-02T12:02:54.938191Z",
     "end_time": "2023-05-02T12:02:55.000254Z"
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this exercise, the label is the **median_house_value**.\n",
    "\n",
    "**<font color='blue'>2. Separate the features and the label (for the train, validation and testing sets).**\n",
    "\n",
    "*Tips: You can use the `pop` function from pandas.*"
   ],
   "metadata": {
    "id": "o3pi3TZGsiTe"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "label_train = train_data.pop('median_house_value')\n",
    "label_test = test_data.pop('median_house_value')\n",
    "label_validation = validation_data.pop('median_house_value')"
   ],
   "metadata": {
    "id": "23-DJwD-gHh6",
    "ExecuteTime": {
     "start_time": "2023-05-02T12:02:54.955256Z",
     "end_time": "2023-05-02T12:02:55.001260Z"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Deep learning algorithms **often require standardized data more than other algorithms** due to their reliance on complex neural network architectures. Here are some reasons:\n",
    "\n",
    "*   It ensures that the neural network is trained on consistent and comparable data. Each layer should receive input data in a consistent format in order to improve the overall performance.\n",
    "*   If the input features are not standardized, the differences in scale between features can result in the neural network assigning higher weights to some features and lower weights to others, which can result in poor performance.\n",
    "*   It helps to reduce the number of iterations required to optimize the neural network's weights, and can also help to prevent the optimizer from getting stuck in local minima.\n",
    "\n",
    "**<font color='blue'>3.a. Standardize the features.**\n",
    "\n",
    "*Tips: You can use the `StandardScaler` function from sklearn.*"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-02T12:02:28.702102Z",
     "end_time": "2023-05-02T12:02:28.734103Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(14711, 1)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "pipeline = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "pipeline.fit_transform(train_data)"
   ],
   "metadata": {
    "id": "VdmJ40mXgIRI",
    "ExecuteTime": {
     "start_time": "2023-05-02T12:04:18.174543Z",
     "end_time": "2023-05-02T12:04:18.215613Z"
    }
   },
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 2.04006331, -1.29917904, -0.7631067 , ...,  0.        ,\n         0.        ,  0.        ],\n       [ 0.64941294, -0.75102774, -0.28711009, ...,  0.        ,\n         0.        ,  0.        ],\n       [ 0.0263617 , -0.5917359 , -0.5251084 , ...,  0.        ,\n         0.        ,  1.        ],\n       ...,\n       [ 1.24255772, -1.35071463,  1.2202125 , ...,  0.        ,\n         0.        ,  1.        ],\n       [ 0.70922586, -0.68075193,  1.06154696, ...,  0.        ,\n         0.        ,  0.        ],\n       [ 0.80392965, -0.79787827,  0.58555035, ...,  0.        ,\n         0.        ,  0.        ]])"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "In deep learning regression, **standardizing the labels can be just as important as standardizing the input features** for the following reasons:\n",
    "\n",
    "\n",
    "*   **Gradient calculations**: The gradients used for optimizing the weights in a deep neural network are calculated based on the loss between the predicted and true labels. If the labels are not standardized, then the gradients will be calculated on a different scale. This can result in unstable gradient updates and slower convergence during training. \n",
    "*   **Activation functions**: The activation functions used in deep neural networks are designed to work best on inputs that are on a similar scale. If the labels are not standardized, then the activations can be biased towards some labels, which can result in lower accuracy. \n",
    "*   **Bias term**: A bias term is often included in the output layer of a deep neural network. If the labels are not standardized, then the bias term can become dominated by the largest values, leading to an imbalanced weighting of the inputs.\n",
    "\n",
    "**<font color='blue'>3.b. Standardize the labels.**\n",
    "\n",
    "*Tips: You can use the `StandardScaler` function from sklearn. Don't use the same as the one for the features.*"
   ],
   "metadata": {
    "id": "fwNL3L8ouBAq"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "pipeline.transform(label_train)"
   ],
   "metadata": {
    "id": "kyeG5JkqgIzD",
    "ExecuteTime": {
     "start_time": "2023-05-02T12:04:49.162241Z",
     "end_time": "2023-05-02T12:04:49.187241Z"
    }
   },
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "StandardScaler()",
      "text/html": "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Architecture"
   ],
   "metadata": {
    "id": "tBEbjl7sokJL"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**TensorFlow Keras** is a high-level API for building and training deep learning models in TensorFlow. TensorFlow Keras **provides a variety of pre-defined layers that can be used to build a neural network**, as well as the ability to create custom layers.\n",
    "\n",
    "The **Dense layer** in TensorFlow is a fully connected layer where each neuron is connected to every neuron in the previous layer. In other words, all input features are connected to all output features.\n",
    "\n",
    "It takes in a tensor as input and applies a linear transformation to produce an output tensor. This linear transformation is defined by a set of weights and biases that are learned during the training process.\n",
    "\n",
    "The Dense layer has many parameters.<br> In this exercise, we will only consider 3 of them:\n",
    "\n",
    "*   **units**: It specifies the number of neurons in the layer. It determines the dimensionality of the output space, i.e., the number of features in the output tensor. For example, if you set units to 10, the Dense layer will output a tensor with 10 features.\n",
    "\n",
    "*   **activation**: It specifies the activation function applied to the output of the layer. Activation functions introduce non-linearity to the model and are an essential component of deep neural networks. You can set this parameter to any activation function provided by TensorFlow, or you can create your own custom activation function. \n",
    "\n",
    "*   **use_bias**: It specifies whether to include a bias term in the layer or not. The bias term is an additional parameter that is added to the output of each neuron. It allows the model to learn an offset from zero, which can be useful for certain types of problems. By default, the use_bias parameter is set to True, but you can set it to False to exclude the bias term from the layer.\n",
    "\n",
    "You can create a Dense layer in TensorFlow using the tf.keras.layers.Dense class:\n",
    "\n",
    "\n",
    "```\n",
    "import tensorflow as tf\n",
    "dense = tf.keras.layers.Dense()\n",
    "```\n",
    "\n",
    "`tf.keras.layers.Dense` [Documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense)\n",
    "\n",
    "**<font color='blue'>1. Create a Dense layer that contains 8 neurons with a ReLU activation function and a bias using the Tensorflow Keras library.**"
   ],
   "metadata": {
    "id": "aMcRFuXKwOAE"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "Hb02bzVngJcC",
    "ExecuteTime": {
     "start_time": "2023-05-02T12:02:55.024803Z",
     "end_time": "2023-05-02T12:02:55.106799Z"
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Performing a forward pass on a TensorFlow Dense layer is straightforward. Given an input tensor, you can apply the Dense layer using the `call` method of the `tf.keras.layers.Dense` class. \n",
    "\n",
    "In python, when you write `dense(x)`, it is interpreted as a call to the `__call__()` method of the Layer class with x as an argument.\n",
    "\n",
    "```\n",
    "output = dense(x_train)\n",
    "```\n",
    "\n",
    "**<font color='blue'>2. Do the forward pass on this layer on the training features.**\n",
    "\n",
    "*Tips: The output of a Dense layer is always of shape (instances, number of neurons)* "
   ],
   "metadata": {
    "id": "2tUrQNHzynCU"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "3VVVVPoXgJ8v",
    "ExecuteTime": {
     "start_time": "2023-05-02T12:05:48.623907Z",
     "end_time": "2023-05-02T12:05:48.637906Z"
    }
   },
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "<tf.Tensor: shape=(14711, 8), dtype=float32, numpy=\narray([[0.08217596, 0.6515413 , 0.        , ..., 0.        , 0.        ,\n        0.        ],\n       [0.3269104 , 0.3273958 , 0.        , ..., 0.        , 0.9378807 ,\n        0.        ],\n       [0.        , 0.757426  , 0.1826669 , ..., 0.        , 0.14885187,\n        0.        ],\n       ...,\n       [0.        , 0.26313612, 0.        , ..., 0.        , 0.        ,\n        0.        ],\n       [0.17719655, 0.        , 0.        , ..., 0.        , 0.32649687,\n        0.        ],\n       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n        0.        ]], dtype=float32)>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "It is possible to **stack multiple layers** by passing the output of the previous layer to the next.\n",
    "\n",
    "**<font color='blue'>3. Create a second dense layer, with one neuron, a linear activation function and a bias.<br> This type of configuration is  typical of an output layer for a regression task.** "
   ],
   "metadata": {
    "id": "P_uUVHWC0OZm"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "SailRMZzgKa4",
    "ExecuteTime": {
     "start_time": "2023-05-02T12:02:55.081787Z",
     "end_time": "2023-05-02T12:02:55.181277Z"
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "In TensorFlow Keras, **a model is a way of organizing layers into a complete graph of computations that transform input data into output predictions**. The `tf.keras.Model` class provides a high-level API for defining and training deep learning models in TensorFlow.\n",
    "\n",
    "***A `tf.keras.Model` is constructed by defining the input and output layers, and any hidden layers that are necessary.*** The input and output layers define the shape of the input data and the shape of the predicted output data, respectively. The hidden layers can be added as necessary to transform the data in the desired way.\n",
    "\n",
    "**The input layer can be defined using the `tf.keras.Input` class.**<br> The only mandatory parameter is the shape of the inputs (the number of features).<br> For a dataset with 15 features, the input layer of the model can be written as:\n",
    "\n",
    "```\n",
    "input_layer = tf.keras.Input(shape=(15,))\n",
    "```\n",
    "\n",
    "`tf.keras.Model` [*Documentation*](https://www.tensorflow.org/api_docs/python/tf/keras/Model)<br>\n",
    "`tf.keras.Input` [*Documentation*](https://www.tensorflow.org/api_docs/python/tf/keras/Input)\n",
    "\n",
    "**<font color='blue'>4.a. Create an input layer with the correct shape (housing dataset).**"
   ],
   "metadata": {
    "id": "lI1oQ8cY1g5T"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "0iovyc0cgLEU",
    "ExecuteTime": {
     "start_time": "2023-05-02T12:02:55.099786Z",
     "end_time": "2023-05-02T12:02:55.181277Z"
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "In TensorFlow, you can chain layers together using a **functional model**. In a functional model, you define the input layer(s) and output layer(s), and then create a \"graph\" of layers that connect the input to the output. **Each layer in the graph takes the output of the previous layer as its input**, and produces an output that can be used as the input to the next layer.\n",
    "\n",
    "\n",
    "```\n",
    "output_1 = tf.keras.layers.Dense(...)(input)\n",
    "output_2 = tf.keras.layers.Dense(...)(output_1)\n",
    "output_3 = tf.keras.layers.Dense(...)(output_2)\n",
    "...\n",
    "```\n",
    "\n",
    "\n",
    "**<font color='blue'>4.b. Create one hidden layer with the tf.keras.Dense class with 8 neurons, a ReLU activation function and a bias.<br> This layer should take the output of the input_layer as input.**"
   ],
   "metadata": {
    "id": "fUTdh2Zr3mJx"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "kjVyq8j6gLlq",
    "ExecuteTime": {
     "start_time": "2023-05-02T12:02:55.110798Z",
     "end_time": "2023-05-02T12:02:55.182257Z"
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**<font color='blue'>4.c. Finally, create one output layer with the tf.keras.Dense class with 1 neurons, a linear activation function and a bias.<br> This layer should take the output of the hidden layer as input..**"
   ],
   "metadata": {
    "id": "G2vhAUQJ4s-V"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "P7WVUlzHgL8h",
    "ExecuteTime": {
     "start_time": "2023-05-02T12:02:55.126253Z",
     "end_time": "2023-05-02T12:02:55.182257Z"
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**The `tf.keras.Model` class accepts three parameters: inputs, outputs and name.** <br>To create a Tensorflow Keras model, you need to specify the input layers in the inputs parameter and the output layers in the outputs parameter.\n",
    "\n",
    "```\n",
    "model = tf.keras.Model(inputs=..., outputs=...)\n",
    "```\n",
    "\n",
    "\n",
    "**<font color='blue'>5. Create the model using the tf.keras.Model class and the layers created at question 4.**"
   ],
   "metadata": {
    "id": "kz8_5j8X49rZ"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "4D9vdaXSgMid",
    "ExecuteTime": {
     "start_time": "2023-05-02T12:02:55.143253Z",
     "end_time": "2023-05-02T12:02:55.183254Z"
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can check the model architecture using:\n",
    "\n",
    "\n",
    "*   the `summary()` method which is a convenient way to get a high-level architecture of the structure of the deep neural network model. \n",
    "*   the `plot_model()` function from `tf.keras.utils` that can be used to visualize the structure of a Keras model. It generates a diagram of the model architecture, which can be saved to a file or displayed on the screen. This function is particularly useful for visualizing complex models with multiple inputs or outputs, or models with branching or merging layers.\n",
    "\n",
    "```\n",
    "model.summary()\n",
    "tf.keras.utils.plot_model(model)\n",
    "```\n",
    "\n",
    "`summary()` [Documentation](https://www.tensorflow.org/api_docs/python/tf/keras/Model#summary)<br>\n",
    "`tf.keras.utils.plot_model()` [Documentation](https://www.tensorflow.org/api_docs/python/tf/keras/utils/plot_model)\n",
    "\n",
    "\n",
    "\n",
    "**<font color='blue'>6.a. Use the `summary()` method on your model.<br>Pay attention to the different elements of the output.**"
   ],
   "metadata": {
    "id": "9yL5V0ET90Rn"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "y3p3XcG0gNDM",
    "ExecuteTime": {
     "start_time": "2023-05-02T12:02:55.157254Z",
     "end_time": "2023-05-02T12:02:55.215333Z"
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**<font color='blue'>6.b. Use the `plot_model()` function on your model.**"
   ],
   "metadata": {
    "id": "RCLURnDI-zpr"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "eQp73fkBgNcV",
    "ExecuteTime": {
     "start_time": "2023-05-02T12:02:55.173258Z",
     "end_time": "2023-05-02T12:02:55.246845Z"
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Training"
   ],
   "metadata": {
    "id": "54b_U0NBomYL"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Before starting the training, we need to specify the loss function, Gradient Descent the algorithm we want to use and the metrics.\n",
    "\n",
    "The `compile()` method is a function in TensorFlow that is used to configure the learning process of a model by specifying the loss, the metrics and the optimizer. It is typically called after a model has been defined, but before it has been trained on any data.\n",
    "\n",
    "The `compile()` method allows you to specify the following important parameters:\n",
    "\n",
    "*   **optimizer**: The optimizer is the algorithm that is used to update the weights of the neural network during training. Some common optimizers include stochastic gradient descent (SGD), Adam, and Adagrad. Tensorflow keras already has builtin losses that you can find in the `tf.keras.optimizers` class.\n",
    "\n",
    "*   **loss**: The loss function is a metric that is used to measure the difference between the predicted output of the model and the true output. The loss function is used by the optimizer to adjust the weights of the neural network to minimize the difference between the predicted and true output. Some common loss functions include mean squared error, categorical cross-entropy, and binary cross-entropy. Tensorflow keras already has builtin losses that you can find in the `tf.keras.losses` class.\n",
    "\n",
    "*   **metrics**: Metrics are used to measure the performance of the model during training and testing. Some common metrics include accuracy, precision, recall, and F1 score. Tensorflow keras already has builtin losses that you can find in the `tf.keras.metrics` class.\n",
    "\n",
    "```\n",
    "model.compile(loss=...,\n",
    "              optimizer=...,\n",
    "              metrics=[...])\n",
    "```\n",
    "\n",
    "In this exercise, we will use the **MSE loss** ([Documentation](https://www.tensorflow.org/api_docs/python/tf/keras/losses/MeanSquaredError)) and the **SGD optimizer** ([Documentation](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers/experimental/SGD)) with a **learning rate of 0.01**.<br> You can add the `learning_rate` parameter directly inside the SGD optimizer.\n",
    "\n",
    "`compile()` [Documentation](https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile)\n",
    "\n",
    "\n",
    "**<font color='blue'>1. Provide the model with its loss and its optimizer using the `compile()` method.**"
   ],
   "metadata": {
    "id": "Dd4ablpW_2Y-"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "TCxPTLBTgOOw",
    "ExecuteTime": {
     "start_time": "2023-05-02T12:02:55.188276Z",
     "end_time": "2023-05-02T12:02:55.277861Z"
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now, you are ready to train the model.\n",
    "\n",
    "The `fit()` method is a function in TensorFlow that is used to train a neural network model on a given dataset. It is typically called after the model has been defined and compiled, and it is used to optimize the weights of the model so that it can make accurate predictions on new data.\n",
    "\n",
    "The `fit()` method allows you to specify the following important parameters:\n",
    "\n",
    "* **x**: The input data to train the model on. This can be a Numpy array or a TensorFlow Dataset.\n",
    "\n",
    "* **y**: The target labels for the input data. This can also be a Numpy array or a TensorFlow Dataset.\n",
    "\n",
    "* **batch_size**: The number of samples that are used in each iteration of training. This can be an integer or None.\n",
    "\n",
    "* **epochs**: The number of times to iterate over the entire dataset. This can be an integer or None.\n",
    "\n",
    "* **validation_data**: The validation data to use during training. This can be a tuple of x_val and y_val, or a TensorFlow Dataset.\n",
    "\n",
    "* **callbacks**: A list of callback functions to use during training. This can include functions to save the weights of the model, or to stop training early if the performance of the model stops improving.\n",
    "\n",
    "The `fit()` method returns a **History object** that contains information about the training history of the model, such as the loss and accuracy metrics on the training and validation data at each epoch. You can use this information to monitor the performance of the model during training and make decisions about when to stop training or adjust the model parameters.\n",
    "\n",
    "```\n",
    "history = model.fit(x=...,\n",
    "                    y=...,\n",
    "                    batch_size=...,\n",
    "                    epochs=...,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    callbacks=[...])\n",
    "```\n",
    "\n",
    "\n",
    "`fit()` [Documentation](https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit)\n",
    "\n",
    "**<font color='blue'>2. Train the model with batch_size=32 and epochs=25.<br> Store the result of the `fit()` method in a variable.**\n",
    "\n",
    "*Tips: Don't forget to fill the `validation_data` parameter with the validation set.*"
   ],
   "metadata": {
    "id": "D98oWHjPENZh"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "yJPPm9uUgOzV",
    "ExecuteTime": {
     "start_time": "2023-05-02T12:02:55.205214Z",
     "end_time": "2023-05-02T12:02:55.324989Z"
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "It is important to look at the **learning curves** (*the training and the validation loss curves*) after the training step.\n",
    "\n",
    "The `fit()` method in TensorFlow **returns a dictionary that contains the training and validation metrics (including the loss) for the model**. The keys of the dictionary correspond to the names of the metrics that were monitored during training, and the values are lists that contain the metric values at each epoch. When no metrics is provided to the model, the dictionary contains at least the loss of the model:\n",
    "\n",
    "* **loss**: The training loss for each epoch.\n",
    "\n",
    "* **val_loss**: The validation loss for each epoch.\n",
    "\n",
    "```\n",
    "history = model.fit(...)\n",
    "metrics_dict = history.history\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "**<font color='blue'>3. Get the training and the validation losses and display them on a line graph using Matplotlib.**"
   ],
   "metadata": {
    "id": "SQ3zRODpGGq-"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "KH_zjylhgPQi",
    "ExecuteTime": {
     "start_time": "2023-05-02T12:02:55.219845Z",
     "end_time": "2023-05-02T12:02:55.325989Z"
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prediction"
   ],
   "metadata": {
    "id": "ghxiF9z5oncv"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "**The `evaluate()` and `predict()` methods are functions in TensorFlow that are used to test a trained neural network model on new data**. These methods can be called after the model has been trained using the `fit()` method.\n",
    "\n",
    "The `evaluate()` method is used to evaluate the performance of the model on a test dataset. It takes as input the test data and returns the loss and metrics for the model. It allows you to evaluate the performance of the model on data that it has not seen during training.\n",
    "\n",
    "```\n",
    "# It takes both the features and the labels\n",
    "model.evaluate(x=..., y=...)\n",
    "```\n",
    "\n",
    "`evaluate()` [Documentation](https://www.tensorflow.org/api_docs/python/tf/keras/Model#evaluate)\n",
    "\n",
    "**<font color='blue'>1.a. Use the `evaluate()` method to evalate the performances of the model on the test set.**"
   ],
   "metadata": {
    "id": "RiL_ypn9HrKW"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "L26MIWS2gPyh",
    "ExecuteTime": {
     "start_time": "2023-05-02T12:02:55.234846Z",
     "end_time": "2023-05-02T12:02:55.325989Z"
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `predict()` method is used to generate predictions from the trained model on new data. It takes as input the test data and returns the predicted output of the model. It allows you to use the trained model to make predictions on new data.\n",
    "\n",
    "```\n",
    "# It only takes the features\n",
    "model.predict(x=...)\n",
    "```\n",
    "\n",
    "`predict()` [Documentation](https://www.tensorflow.org/api_docs/python/tf/keras/Model#predict)\n",
    "\n",
    "**<font color='blue'>1.b. Use the `predict()` method to evaluate the performances of the model on the test set.**"
   ],
   "metadata": {
    "id": "v9Jc6cQEIcsJ"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "Z-jdDwZ6gQeo",
    "ExecuteTime": {
     "start_time": "2023-05-02T12:02:55.251846Z",
     "end_time": "2023-05-02T12:02:55.326992Z"
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "The predictions are in the standardized format.\n",
    "\n",
    "**<font color='blue'>2.a. Apply the inverse preprocessing transformation on the predictions.**\n",
    "\n",
    "*Tips: The sklearn preprocessing functions provide an `inverse_transform` method.*"
   ],
   "metadata": {
    "id": "LIT_7CmMI36U"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "94l2UK6VgQ1L",
    "ExecuteTime": {
     "start_time": "2023-05-02T12:02:55.267845Z",
     "end_time": "2023-05-02T12:02:55.326992Z"
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**<font color='blue'>2.b. Compute the RMSE score.**\n",
    "\n",
    "*Tips: You can get the RMSE function from the sklearn library.*"
   ],
   "metadata": {
    "id": "QTV6Fa0pJwby"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "y_RO92tXgRPj",
    "ExecuteTime": {
     "start_time": "2023-05-02T12:02:55.280844Z",
     "end_time": "2023-05-02T12:02:55.326992Z"
    }
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Classification"
   ],
   "metadata": {
    "id": "DWF6LYZhuUKm"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The MLP architecture, the loss and the metrics are different for classification tasks.\n",
    "\n",
    "**<font color='blue'>Build and train an MLP model for the breast dataset.**\n",
    "\n",
    "*Tips: Don't forget to use the correct cross-entropy and the correct output layer activation function.*"
   ],
   "metadata": {
    "id": "OVkC-3AE9EW3"
   }
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "1Me7SznhgTGE",
    "ExecuteTime": {
     "start_time": "2023-05-02T12:02:55.298474Z",
     "end_time": "2023-05-02T12:02:55.326992Z"
    }
   },
   "execution_count": 9,
   "outputs": []
  }
 ]
}
