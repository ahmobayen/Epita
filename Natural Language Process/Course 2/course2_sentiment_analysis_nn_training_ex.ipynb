{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "course2_sentiment_analysis_nn_training_ex.ipynb",
   "provenance": [
    {
     "file_id": "1UcqV7dVM8DE7kCjCTwiBtXaNBm1pkeVr",
     "timestamp": 1622912798930
    }
   ],
   "authorship_tag": "ABX9TyNTWkAU4sFCEYvQ0IAY4bQQ"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "S_2Ay0Fp6Bbs",
    "ExecuteTime": {
     "end_time": "2023-06-12T14:38:45.494077500Z",
     "start_time": "2023-06-12T14:38:41.633103700Z"
    }
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.layers import Dense, Dropout"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2CIb2eM9BEx"
   },
   "source": [
    "Definition of a plot function for training result visualization"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_C-ARKUf6Zs4",
    "ExecuteTime": {
     "end_time": "2023-06-12T14:38:56.637555300Z",
     "start_time": "2023-06-12T14:38:56.589163700Z"
    }
   },
   "source": [
    "def plot_results(history):\n",
    "    hist_df = pd.DataFrame(history.history)\n",
    "    hist_df.columns = [\"loss\", \"accuracy\", \"val_loss\", \"val_accuracy\"]\n",
    "    hist_df.index = np.arange(1, len(hist_df) + 1)\n",
    "\n",
    "    fig, axs = plt.subplots(nrows=2, sharex=True, figsize=(16, 10))\n",
    "    axs[0].plot(hist_df.val_accuracy, lw=3, label='Validation Accuracy')\n",
    "    axs[0].plot(hist_df.accuracy, lw=3, label='Training Accuracy')\n",
    "    axs[0].set_ylabel('Accuracy')\n",
    "    axs[0].set_xlabel('Epoch')\n",
    "    axs[0].grid()\n",
    "    axs[0].legend(loc=0)\n",
    "    axs[1].plot(hist_df.val_loss, lw=3, label='Validation Loss')\n",
    "    axs[1].plot(hist_df.loss, lw=3, label='Training Loss')\n",
    "    axs[1].set_ylabel('Loss')\n",
    "    axs[1].set_xlabel('Epoch')\n",
    "    axs[1].grid()\n",
    "    axs[1].legend(loc=0)\n",
    "\n",
    "    plt.show();"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AEGjlF9S9jJ9"
   },
   "source": [
    "## Preprocessing of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MvHI_pLN9s2L"
   },
   "source": [
    "We get the IMDB dataset directly from the tensorflow_datasets API and we do the usual preprocessing before feeding a neural network"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pLr7YiH96eB2",
    "ExecuteTime": {
     "end_time": "2023-06-12T14:40:59.786630700Z",
     "start_time": "2023-06-12T14:39:52.345380Z"
    }
   },
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "datasets, info = tfds.load(\"imdb_reviews\", as_supervised=True, with_info=True)\n",
    "\n",
    "train_size = info.splits[\"train\"].num_examples\n",
    "batch_size = 32\n",
    "\n",
    "train_set = datasets[\"train\"].shuffle(10000).repeat().batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "test_size = info.splits[\"test\"].num_examples\n",
    "test_set = datasets[\"test\"].repeat().batch(batch_size).prefetch(tf.data.AUTOTUNE)"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\amirh\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0...\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "Dl Completed...: 0 url [00:00, ? url/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad229ffdfdab491bbe49bf59fcc316ed"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Dl Size...: 0 MiB [00:00, ? MiB/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d8e5762e458c47fa84f5bcd77ea1f257"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating splits...:   0%|          | 0/3 [00:00<?, ? splits/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bf7ca66655034a199f62229a6a168d44"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating train examples...: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3af5a47461ba4c998a3dac79e50ba6e5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Shuffling C:\\Users\\amirh\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incomplete3Q7U66\\imdb_reviews-train…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1bc2a750e4b24577a951e94eba185f07"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating test examples...: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "513290acfe654d4b84333b2112191aea"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Shuffling C:\\Users\\amirh\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incomplete3Q7U66\\imdb_reviews-test.…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0d125afa6980411ca4b966b3334ad2d5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating unsupervised examples...: 0 examples [00:00, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "35543d26968f4d2296c82888affb96f1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Shuffling C:\\Users\\amirh\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0.incomplete3Q7U66\\imdb_reviews-unsup…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7bc644794aeb4d58bfbe65785b227d48"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1mDataset imdb_reviews downloaded and prepared to C:\\Users\\amirh\\tensorflow_datasets\\imdb_reviews\\plain_text\\1.0.0. Subsequent calls will reuse this data.\u001B[0m\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxitmaEZA64u"
   },
   "source": [
    "## Use of a pretrained embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PjjSBh_H-LRA"
   },
   "source": [
    "We use of pretrained embedding directly from tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zU7z0p_V7O7A",
    "ExecuteTime": {
     "end_time": "2023-06-12T14:42:01.960273600Z",
     "start_time": "2023-06-12T14:41:45.059122200Z"
    }
   },
   "source": [
    "embed = hub.load(\"https://tfhub.dev/google/tf2-preview/nnlm-en-dim50/1\")"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ab7EQzFmAXmu"
   },
   "source": [
    "We test on two (famous) lines and check the shapes of the embedding results"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YQR2XvIk7S03",
    "ExecuteTime": {
     "end_time": "2023-06-12T14:42:05.772466200Z",
     "start_time": "2023-06-12T14:42:05.707457200Z"
    }
   },
   "source": [
    "embeddings = embed([\"A thing of beauty is a joy forever\", \"If by dull rhymes our English must be chain'd\"])\n",
    "print(embeddings)\n",
    "print(embeddings.shape)"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.03275988  0.18106811  0.13030443  0.05100623  0.12367279 -0.11072872\n",
      "   0.1655957  -0.0049278  -0.3281556   0.05204761  0.17150185  0.01282718\n",
      "  -0.09332222  0.1672171  -0.05711355 -0.22492586 -0.15962309 -0.00958291\n",
      "  -0.11166596 -0.42931503 -0.0194127  -0.20494537  0.25295272  0.05954154\n",
      "  -0.25411132  0.12579551 -0.16218384 -0.10604351  0.27133545 -0.15765025\n",
      "  -0.31424785  0.21318786 -0.10896667  0.14070608 -0.24665987  0.1579746\n",
      "   0.24865562  0.04819695  0.10051076 -0.24969979  0.15491936 -0.0360333\n",
      "   0.07346644  0.10915987 -0.08220651  0.12550174  0.16840625 -0.01693668\n",
      "   0.0715794  -0.04162662]\n",
      " [ 0.16800539  0.24028125 -0.30071175  0.07007764 -0.18024668  0.07986181\n",
      "   0.05427119 -0.28110817 -0.22582981  0.26624134  0.13623291 -0.11988997\n",
      "   0.16064322 -0.04873525 -0.08858649 -0.15337813  0.00109797 -0.26315662\n",
      "   0.3372981  -0.14884004  0.17933601 -0.12853579 -0.15982151 -0.10252967\n",
      "  -0.03884843  0.08044805 -0.20275603 -0.17167023  0.20971875 -0.12899558\n",
      "   0.07407399  0.237014    0.14208776 -0.33200854 -0.12605904 -0.07594581\n",
      "   0.02684807  0.00552503  0.09870575 -0.2602448   0.21202575 -0.0655203\n",
      "  -0.14746019 -0.1037299  -0.02173514  0.0199495  -0.1951208   0.1663805\n",
      "   0.06281476  0.05411559]], shape=(2, 50), dtype=float32)\n",
      "(2, 50)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aXJvUiwrA-4i"
   },
   "source": [
    "## Neural network model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5t7Et6bMGoz4"
   },
   "source": [
    "Build a neural network using keras sequential layers\n",
    "\n",
    "(you may have a look at https://keras.io/api/layers/)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kobUaul57W0y",
    "ExecuteTime": {
     "end_time": "2023-06-12T14:53:02.276665100Z",
     "start_time": "2023-06-12T14:53:02.232479400Z"
    }
   },
   "source": [
    "# Question 1: Build a neural network using relevant layers, dimensions and activation function (the input layer is already defined to help you)\n",
    "model = tf.keras.models.Sequential([\n",
    "    hub.KerasLayer(embed,\n",
    "                   dtype=tf.string, input_shape=[], output_shape=[50]),\n",
    "    Dense(units=128, activation='relu'),\n",
    "    Dense(units=300, activation='relu'),\n",
    "    Dense(units=1, activation='sigmoid')\n",
    "])\n"
   ],
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jUFjZK83Gs99"
   },
   "source": [
    "We check that everything is fine with the model as we defined it"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "u7eZA1saGuXa",
    "ExecuteTime": {
     "end_time": "2023-06-12T14:53:04.050550100Z",
     "start_time": "2023-06-12T14:53:04.026549800Z"
    }
   },
   "source": [
    "model.summary()"
   ],
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer_4 (KerasLayer)  (None, 50)                48190600  \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 128)               6528      \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 300)               38700     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 301       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,236,129\n",
      "Trainable params: 45,529\n",
      "Non-trainable params: 48,190,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kg70hqlPJbaU"
   },
   "source": [
    "We compile the model, choosing the relevant loss function, optimizer and metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IkIzJDn9G0Av"
   },
   "source": [
    "(You may have a look at\n",
    "https://keras.io/api/losses/\n",
    "and\n",
    "https://keras.io/api/optimizers/)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rYIi8jps7aFa",
    "ExecuteTime": {
     "end_time": "2023-06-12T14:56:09.558237500Z",
     "start_time": "2023-06-12T14:56:09.543184Z"
    }
   },
   "source": [
    "# Question 2: Choose a relevant loss fonction and optimizer for the training\n",
    "loss_function =  tf.keras.losses.BinaryCrossentropy()\n",
    "optimizer =  tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "model.compile(loss=loss_function, optimizer=optimizer,\n",
    "              metrics=[\"accuracy\"])"
   ],
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "siQfzR5oHHni"
   },
   "source": [
    "We train the model on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "O6TTGWXb7eEn",
    "ExecuteTime": {
     "end_time": "2023-06-12T14:59:55.566932100Z",
     "start_time": "2023-06-12T14:58:25.849944100Z"
    }
   },
   "source": [
    "# Question 3: Choose relevant values for epochs\n",
    "# (Start with small values for epochs in order to save some computation time)\n",
    "epochs =  20\n",
    "\n",
    "history = model.fit(train_set, steps_per_epoch=train_size // batch_size, epochs=epochs, validation_data=test_set,\n",
    "                    validation_steps=test_size // batch_size)"
   ],
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "781/781 [==============================] - 5s 6ms/step - loss: 0.3246 - accuracy: 0.8558 - val_loss: 0.6729 - val_accuracy: 0.7176\n",
      "Epoch 2/20\n",
      "781/781 [==============================] - 5s 6ms/step - loss: 0.3147 - accuracy: 0.8604 - val_loss: 0.6868 - val_accuracy: 0.7246\n",
      "Epoch 3/20\n",
      "781/781 [==============================] - 4s 6ms/step - loss: 0.3042 - accuracy: 0.8670 - val_loss: 0.7185 - val_accuracy: 0.7238\n",
      "Epoch 4/20\n",
      "781/781 [==============================] - 5s 6ms/step - loss: 0.2948 - accuracy: 0.8723 - val_loss: 0.7403 - val_accuracy: 0.7156\n",
      "Epoch 5/20\n",
      "781/781 [==============================] - 5s 6ms/step - loss: 0.2849 - accuracy: 0.8754 - val_loss: 0.7479 - val_accuracy: 0.7159\n",
      "Epoch 6/20\n",
      "781/781 [==============================] - 4s 6ms/step - loss: 0.2772 - accuracy: 0.8804 - val_loss: 0.7599 - val_accuracy: 0.7069\n",
      "Epoch 7/20\n",
      "781/781 [==============================] - 4s 6ms/step - loss: 0.2677 - accuracy: 0.8850 - val_loss: 0.7772 - val_accuracy: 0.7155\n",
      "Epoch 8/20\n",
      "781/781 [==============================] - 4s 6ms/step - loss: 0.2591 - accuracy: 0.8888 - val_loss: 0.7848 - val_accuracy: 0.7177\n",
      "Epoch 9/20\n",
      "781/781 [==============================] - 4s 6ms/step - loss: 0.2485 - accuracy: 0.8950 - val_loss: 0.8014 - val_accuracy: 0.7126\n",
      "Epoch 10/20\n",
      "781/781 [==============================] - 4s 6ms/step - loss: 0.2393 - accuracy: 0.9004 - val_loss: 0.8362 - val_accuracy: 0.7035\n",
      "Epoch 11/20\n",
      "781/781 [==============================] - 4s 6ms/step - loss: 0.2321 - accuracy: 0.9035 - val_loss: 0.8618 - val_accuracy: 0.7041\n",
      "Epoch 12/20\n",
      "781/781 [==============================] - 4s 6ms/step - loss: 0.2224 - accuracy: 0.9088 - val_loss: 0.9025 - val_accuracy: 0.7114\n",
      "Epoch 13/20\n",
      "781/781 [==============================] - 4s 6ms/step - loss: 0.2145 - accuracy: 0.9114 - val_loss: 0.8832 - val_accuracy: 0.7037\n",
      "Epoch 14/20\n",
      "781/781 [==============================] - 4s 6ms/step - loss: 0.2043 - accuracy: 0.9169 - val_loss: 0.9253 - val_accuracy: 0.6963\n",
      "Epoch 15/20\n",
      "781/781 [==============================] - 5s 6ms/step - loss: 0.1939 - accuracy: 0.9229 - val_loss: 0.9735 - val_accuracy: 0.7055\n",
      "Epoch 16/20\n",
      "781/781 [==============================] - 5s 6ms/step - loss: 0.1891 - accuracy: 0.9251 - val_loss: 0.9838 - val_accuracy: 0.7019\n",
      "Epoch 17/20\n",
      "781/781 [==============================] - 5s 6ms/step - loss: 0.1804 - accuracy: 0.9310 - val_loss: 0.9881 - val_accuracy: 0.7008\n",
      "Epoch 18/20\n",
      "781/781 [==============================] - 4s 6ms/step - loss: 0.1714 - accuracy: 0.9342 - val_loss: 1.0280 - val_accuracy: 0.6927\n",
      "Epoch 19/20\n",
      "781/781 [==============================] - 4s 6ms/step - loss: 0.1657 - accuracy: 0.9378 - val_loss: 1.0530 - val_accuracy: 0.7050\n",
      "Epoch 20/20\n",
      "781/781 [==============================] - 4s 6ms/step - loss: 0.1573 - accuracy: 0.9411 - val_loss: 1.0907 - val_accuracy: 0.6987\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h15OAnNqBdP4"
   },
   "source": [
    "## Result visualization"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WXjErDMg7lTD",
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-06-12T15:00:14.614838600Z"
    }
   },
   "source": [
    "plot_results(history)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wgshsvFRKC4_"
   },
   "source": [
    "# Question 4: What can you tell about the results? Does it seem satisfying to you? Do you see any hint of an over-fitting? If yes, what kind of layers can you use into the Keras model in order to prevent this phenomenon?"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}
